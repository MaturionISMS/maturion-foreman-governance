# PLATFORM TREE METRICS ENGINE SPECIFICATION  
Version: 1.0  
Status: Analytics & Scoring Specification  
Owner: Johan  
Last Updated: YYYY-MM-DD  

--------------------------------------------------------------------------------
# 1. PURPOSE

The Metrics Engine is responsible for computing the **health, risk, stability,  
and performance metrics** for each node in the Maturion Platform Tree.

It answers:

- How healthy is this node right now?  
- How has it behaved over time?  
- Is it improving or degrading?  
- How much risk does instability here create for the rest of the system?  
- Is this a minor anomaly or a structural problem?  
- Where should Johan and Maturion focus attention first?  

The engine provides quantitative metrics that drive:

- node status colours (live view)  
- trend colours (analytics view)  
- hotspot detection  
- Maturion diagnostics reasoning  
- predictive insights in later phases  

--------------------------------------------------------------------------------
# 2. METRICS SCOPE

Metrics are defined at the **node level**, but they roll up to:

- parent nodes  
- layers (e.g. Embodiments, Platform Architecture)  
- overall system view  

Metrics cover:

1. **Availability & Status**  
2. **Incidents & Watchdogs**  
3. **Drift & Behavioural Stability**  
4. **Performance & Cost**  
5. **Governance & Autonomy**  

Each metric must be:

- well-defined  
- reproducible  
- explainable  
- auditable  

--------------------------------------------------------------------------------
# 3. METRICS TAXONOMY

The Metrics Engine defines the following primary metrics per node:

1. **UptimePercentage**  
2. **RedTimePercentage**  
3. **AmberTimePercentage**  
4. **IncidentFrequency**  
5. **HighSeverityIncidentFrequency**  
6. **WatchdogWarningRate**  
7. **WatchdogErrorRate**  
8. **DriftScore**  
9. **LatencyScore**  
10. **ErrorRateScore**  
11. **CostUsageScore**  
12. **AutonomyRiskScore**  
13. **OverallHealthScore**  
14. **HotspotScore**  

Not all metrics apply equally to all node types (e.g. a purely philosophical node may skip latency metrics), but the engine must handle all gracefully.

--------------------------------------------------------------------------------
# 4. RAW INPUTS

The Metrics Engine consumes:

- NodeHealthSnapshot records (Phase 4)  
- NodeStatus history  
- IWMS incident records  
- Watchdog outputs (Guardian, Sentinel, Arbiter)  
- Runtime telemetry (latency, errors, cost)  
- Governance events (autonomy violations, forbidden actions)  

These are treated as **raw signals**, and the engine derives normalized scores.

--------------------------------------------------------------------------------
# 5. METRIC DEFINITIONS & FORMULAS

## 5.1 UptimePercentage

Represents the fraction of time a node has been in a **non-red** state.

Over a window W (e.g. 7 days):

```text
UptimePercentage = (timeNotRed / totalWindowTime) * 100
Where timeNotRed includes:

green

amber

blue

purple

grey

5.2 RedTimePercentage
text
Copy code
RedTimePercentage = (timeRed / totalWindowTime) * 100
Red = severe failure or blocking issue.

5.3 AmberTimePercentage
text
Copy code
AmberTimePercentage = (timeAmber / totalWindowTime) * 100
Amber = degraded, unstable, at-risk but not fully broken.

5.4 IncidentFrequency
Number of incidents per unit time for the node:

text
Copy code
IncidentFrequency = incidentCount / windowDurationInHours
Can be scaled per day/week as needed.

5.5 HighSeverityIncidentFrequency
Same as above but only where:

severity in {HIGH, CRITICAL}

text
Copy code
HighSeverityIncidentFrequency =
  highSeverityIncidentCount / windowDurationInHours
5.6 WatchdogWarningRate
Rate of warnings generated by all watchdogs:

text
Copy code
WatchdogWarningRate = warningEvents / windowDurationInHours
5.7 WatchdogErrorRate
Rate of error-level watchdog signals:

text
Copy code
WatchdogErrorRate = errorEvents / windowDurationInHours
These are strong indicators of systemic issues.

5.8 DriftScore
DriftScore is a normalized indicator of behavioural instability (especially from Sentinel).

For a window W:

text
Copy code
DriftScore = normalize(‚àë driftEventsWeighted)
Where:

driftEventsWeighted weighs:

magnitude of drift

recency

severity

normalize() maps to [0, 1] or [0, 100].

Proposed scale:

0‚Äì20 ‚Üí very stable

21‚Äì40 ‚Üí mild drift

41‚Äì60 ‚Üí concerning drift

61‚Äì80 ‚Üí high drift

81‚Äì100 ‚Üí critical drift

5.9 LatencyScore
Measures operational responsiveness of a node.

text
Copy code
LatencyScore = normalize(meanLatencyMs, lowerIsBetter)
Normalization may map:

< 100ms ‚Üí ‚Äúexcellent‚Äù

100‚Äì300ms ‚Üí ‚Äúgood‚Äù

300‚Äì1000ms ‚Üí ‚Äúdegraded‚Äù

1000ms ‚Üí ‚Äúsevere‚Äù

5.10 ErrorRateScore
Normalizes operational error rate:

text
Copy code
ErrorRateScore = normalize(errorRate, lowerIsBetter)
Where errorRate may be:

failed checks / total checks

failed calls / total calls

5.11 CostUsageScore
Represents how cost-effective this node‚Äôs operations are in context.

Examples:

text
Copy code
CostUsageScore = normalize(costUsageRelativeToBudget, lowerIsBetter)
costUsageRelativeToBudget: % of allowed budget used in the window

could be weighted by severity of tasks (e.g. high-tier model usage only where justified)

5.12 AutonomyRiskScore
Measures how risky autonomy is at this node, based on:

how often autonomy is used

how high autonomy level is

how often autonomy correlates with incidents

how often governance blocks actions

Example logic:

text
Copy code
AutonomyRiskScore =
  autonomyUsageWeight +
  autonomyIncidentWeight +
  governanceBlockWeight;
Normalized to [0, 100].

5.13 OverallHealthScore
Composite score summarizing a node‚Äôs state.

Example concept:

text
Copy code
OverallHealthScore = clamp(
    100
    - f1(RedTimePercentage)
    - f2(IncidentFrequency)
    - f3(HighSeverityIncidentFrequency)
    - f4(DriftScore)
    - f5(ErrorRateScore)
    - f6(CostUsageScore)
    - f7(AutonomyRiskScore),
  0,
  100
)
Where f1..f7 are weight functions.

Goal:

80‚Äì100 ‚Üí healthy

60‚Äì79 ‚Üí acceptable but watch

40‚Äì59 ‚Üí concerning

0‚Äì39 ‚Üí unhealthy

5.14 HotspotScore
Used for hotspot detection and ranking.

Example:

text
Copy code
HotspotScore =
  w1 * RedTimePercentage +
  w2 * HighSeverityIncidentFrequency +
  w3 * DriftScore +
  w4 * ErrorRateScore +
  w5 * AutonomyRiskScore;
Where w1..w5 are tuned weights.

Nodes with highest HotspotScore are shown as key focus areas.

6. NODE-TYPE-SPECIFIC METRICS
Different node types emphasise different metrics:

6.1 Constitutional / Philosophy Nodes (Levels 0‚Äì2)
Primary metrics:

RedTimePercentage

IncidentFrequency (especially constitutional violations)

DriftScore (governance-related)

No latency or cost metrics needed; they are conceptual nodes.

6.2 Intelligence & Governance Nodes (Levels 3‚Äì4)
Key metrics:

RedTimePercentage

IncidentFrequency

DriftScore

WatchdogErrorRate

Latency and cost are less relevant, except where they map to governance API performance.

6.3 Embodiments (Level 5)
Key metrics:

DriftScore

IncidentFrequency

AutonomyRiskScore

ErrorRateScore

6.4 Platform Architecture & Modules (Levels 6‚Äì8)
Key metrics:

UptimePercentage

RedTimePercentage

ErrorRateScore

LatencyScore

CostUsageScore

IncidentFrequency

7. METRIC CALCULATION PIPELINE
Step 1 ‚Äî Snapshot Collection
NodeHealthSnapshot created regularly

Incidents and watchdog events aggregated

Step 2 ‚Äî Window Selection
Metrics computed for each time window:

last 24 hours

last 7 days

last 30 days

Step 3 ‚Äî Raw Aggregations
Count durations in each status

Count incidents and watchdog events

Compute means for latency, errorRate, drift

Step 4 ‚Äî Normalization
Normalize raw values to [0, 100] per metric

Use sensible defaults for missing data

Step 5 ‚Äî Composite Metrics
Compute OverallHealthScore

Compute HotspotScore

Compute TrendDirection (Phase 4)

Step 6 ‚Äî Storage
Persist NodeTrendMetrics

Optionally cache composite scores for fast access

8. RELATION TO STATUS COLOURS
The Metrics Engine does not directly set colours; it provides scores that
inform status decisions.

Basic guidelines:

RedTimePercentage high + recent incidents ‚Üí likely üî¥

AmberTimePercentage moderate + driftScore rising ‚Üí likely üü°

OverallHealthScore > 80 ‚Üí üü¢ (if no red/amber present)

ARC override / purple conditions override metric-based colours

Metrics are inputs to status, not the only deciding factor.

9. MATURION‚ÄôS USE OF METRICS
Maturion uses metrics for:

diagnostics (Phase 3)

prioritisation (‚Äúwhere should we focus?‚Äù)

strategy (‚Äúis this a one-off bug or systemic issue?‚Äù)

governance reasoning (‚Äúis autonomy safe here?‚Äù)

cost vs safety trade-offs (‚Äúis this subsystem too expensive for the risk it covers?‚Äù)

Every diagnostics response should be able to cite metrics:

‚ÄúThis node has a high HotspotScore because it has 40% red time and
frequent high-severity incidents in the last 7 days.‚Äù

10. GOVERNANCE & SAFETY CONSIDERATIONS
The Metrics Engine must:

NOT include tenant-private information in global metrics

NOT infer cross-tenant comparisons

Respect Tenant Isolation Standard at all times

Treat world-model and constitutional nodes with extra caution

Avoid automatic decisions that alter constitution or memory architecture

Any attempt to use metrics to:

weaken guardrails

justify dangerous autonomy

rationalize bypassing governance

‚Üí MUST be blocked by Guardian + Arbiter + Sentinel and generate an IWMS incident.

11. IMPLEMENTATION STRATEGY
Phase A ‚Äî Baseline Metrics
Implement Uptime, Red/Amber percentages, IncidentFrequency, Watchdog rates

Phase B ‚Äî Behavioural & Performance Metrics
Add DriftScore, LatencyScore, ErrorRateScore

Phase C ‚Äî Composite Scores
Implement OverallHealthScore and HotspotScore

Tune weights iteratively with Johan

Phase D ‚Äî Refinement
Adjust formulas using real-world data

Add config-based weight overrides (configurable, not hard-coded)

12. TESTING REQUIREMENTS
12.1 Unit Tests
Each metric formula correctly implemented

Edge cases (no data, partial data, contradictory signals)

12.2 Scenario-Based Tests
Using synthetic data sets:

‚ÄúAlways green‚Äù node ‚Üí high health score

‚ÄúFlaky‚Äù node (frequent red/green flips) ‚Üí volatile / high drift

‚ÄúChronic red‚Äù node ‚Üí high HotspotScore, low health

12.3 Integration Tests
Metrics computed from NodeHealthSnapshots

Backend endpoints return consistent values for trends and hotspots

Maturion correctly consumes and explains metrics

13. EXTENSIBILITY
Future metrics could include:

fairness / bias indicators

explainability metrics

safety violation proximity scores

model-routing efficiency scores

The engine must be extendable without breaking existing nodes or the API.

